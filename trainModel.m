clear;clc;

% Create environment
gameEnvironment = mancalaRandom;
observationInfo = getObservationInfo(gameEnvironment);
actionInfo = getActionInfo(gameEnvironment);

% Choose learning rate
criticOptimizerOptions = rlOptimizerOptions( ...
    'LearnRate',1e-4);

% Deep Q-Learning options
agentOptions = rlDQNAgentOptions(...
    'UseDoubleDQN',false, ...    
    'TargetUpdateMethod',"periodic", ...
    'TargetUpdateFrequency',100, ...   
    'MiniBatchSize',128, ...
    'ExperienceBufferLength',2000, ...
    'CriticOptimizerOptions', criticOptimizerOptions);

% Neural Network structure
network = [
    featureInputLayer(prod(observationInfo.Dimension), ...
        'Normalization', 'none', 'Name', 'state')
    fullyConnectedLayer(256, 'Name', 'CriticStateFC1')
    reluLayer('Name', 'CriticRelu1')
    fullyConnectedLayer(256, 'Name', 'CriticStateFC2')
    reluLayer('Name', 'CriticRelu2')
    fullyConnectedLayer(length(actionInfo.Elements), ...
        'Name', 'output')];

% Create agent
critic = rlVectorQValueFunction(network,observationInfo,actionInfo);
agent = rlDQNAgent(critic,agentOptions);

% Select training options
trainingOptions = rlTrainingOptions( ...
    "MaxEpisodes", 10000, ...
    "ScoreAveragingWindowLength", 100, ...
    "SaveAgentCriteria", "EpisodeCount", ...
    "SaveAgentValue", 1, ...
    "SaveAgentDirectory", "savedAgents");

% Train the model
trainingData = train(agent,gameEnvironment,trainingOptions);